* Recursive function is not supported by SYCL/OpenCL.  Hopefully DPC++
  will support it.  It's crucial to the WarpX code.

* In AMReX, we have GpuTuple that we successfully use it on device
  with CUDA.  But GpuTuple is not standard layout type.  So SYCL does
  not like.  It is however trivially copyable (i.e., memcpy safe).
  Why is memcpy not enough for SYCL?  Is this because it's based on
  OpenCL?  Will DPC++ relax this requirement?

* assert(0) works on device to some extent.  It prints out a message
  on which thread calls it.  But it does not abort the run.  Is that
  expected?  Am I right in expecting it throws an async error that
  will be handled by the async error handler we give to the queue.
  See `amrex_sync_error_handler` and how it is used in
  `amrex/Src/Base/AMReX_GpuDevice.cpp`, and how `wait_and_throw` is
  called to try to catch the async error. Update: It appears that assert
  is not supposed to throw any errors.

* SYCL_EXTERNAL works on functions.  Does Intel have plan to support
  it for variables?

* cmath. This link lists unsupported cmath functions on device,
  including abs, ceil, copysign, etc.  Will they be supported
  eventually?  What does this mean? "Device libraries can't support
  both single and double precision as some underlying device may not
  support double precision."
  https://github.com/intel/llvm/blob/sycl/sycl/doc/extensions/C-CXX-StandardLibrary/C-CXX-StandardLibrary.rst

* How to prefetch USM from host to device and from device to host?

* Device properties.  How to get the maximal number of work items
  allowed on a compute unit?  In the intel/llvm github repo, there is
  `sycl::info::device::max_work_items_per_compute_unit`.  So maybe it
  has been implemented, but not in beta4 yet.  Are there limits on how
  many groups can be launched?  If there are, how to query it?

* Free memory.  Could not find something like `cudaMemGetInfo(size_t*
  free, size_t* total)`, where `free` is free memory in bytes and
  `total` is total memory in bytes.  We need this to avoid
  oversubscribing memory. 

* Random number generation.  What does DPC++ provide for random number
  generation?  For CUDA, AMReX users can call `amrex::Random()` from
  anywhere in their host and/or device code.  The initialization of
  random number states is expensive in CUDA.  So we initialize them in
  amrex::Initialize() and store them in global variable,

  namespace {
    __device__ randState_t* d_states_d_ptr;
  } 

  Then `amrex::Random()` can use `d_states_d_ptr`.  Because DPC++ does
  not appear to support global variable in device memory, how do we do
  this?

* Host callback.  Currently we simply synchronize to get around the
  issue.  For most cases, this should not affect performance much.

* Reduction.  Currently, we have implemented sum, min, max, etc. using
  atomics.  To get better performance, we should use collectives and
  subgroup primitives DPC++ provides.  For now, we could wait till the
  software environment is more mature, because it's not clear whether
  all the related extensions proposed by Intel have been implemented.

* Scan.  We need to look into what DPC++ provides.  We will try to use
  it first.  Later we might want to implement our own if necessary.

* get_pointer_type doesn't seem to exist in beta4 yet.  So we will
  wait.

* Local memory.  Unless Intel supports static local memory allocation
  (e.g., something like __local_memory__ a[256]), we will have to pass
  a pointer to local memory to where it needs.

* ftrapv.  The compiler doesn't like `-ftrapv`.
  https://github.com/WeiqunZhang/dpcpp/tree/master/ftrapv

* GpuTuple.  GpuTuple<int> is standard layout and the compiler doesn't
  complain when it's captured by value.  But it's value seems wrong.

* DONE [[sycl::intel_reqd_sub_group_size(32)]] doesn't seem to exist in
  beta4 yet.  So we will wait.  Question.  Is there a function to
  query the hardware sub group size? Update:
  `cl::intel_reqd_sub_group_size()` works.  We use clang diagnostic
  ignored, push and pop to suppress the warning on unknown attribute.
