#!/bin/bash -l
#SBATCH -C gpu
#SBATCH -t 00:05:00 
#SBATCH -J AMREX_GPU
#SBATCH -o AMREX_GPU.o%j
#SBATCH -A m1759
#SBATCH -N 1
#SBATCH -n 8 
#SBATCH -c 10
#SBATCH --gres=gpu:8
#SBATCH --ntasks-per-node=8

# Note: Given exclusive configuration mode,
#       you MUST specify your desired resources up top like this.
#       Cannot put it in the srun line alone.
#       (You can force lower than your full request in the srun line,
#        or put the configuration again for safety, but shouldn't be needed.)
# ============
# -N =                nodes
# -n =                tasks (MPI ranks)
# -c =                CPU per task (full coriGPU node, c*n <= 80)
# --gres=gpu: =       GPUs per node (full coriGPU node, 8)
# --ntasks-per-node = number of tasks (MPI ranks) per node (full node, 8)
#

# For one node:  -N 1, -n  8, -c 10, --gres=gpu:8 --ntasks-per-node 8
# For two nodes: -N 2, -n 16, -c 10, --gres=gpu:8 --ntasks-per-node 8

# salloc commands:
# (Make sure the appropriate module is loaded to see the gpu partition, esslurm.)
# ================
# Single GPU. (If you don't require an independent node, please use a shared node.)
# salloc -N 1 -t 2:00:00 -c 10 -C gpu --gres=gpu:1 -A m1759
# Single node:
# salloc -N 1 -t 2:00:00 -c 80 -C gpu --exclusive --gres=gpu:8 -A m1759 
# Multi node:
# salloc -N 2 -t 2:00:00 -c 80 -C gpu --exclusive --gres=gpu:8 -A m1759


EXE=./main3d.gnu.TPROF.MPI.CUDA.ex
INPUTS=inputs

# Basic job submissions:
# =============================
# Run inside the current salloc session using available resources.
# Change parameters to match available resources & run with "./run.corigpu"
# srun -n 8 -c 10 --gres=gpu:8 ${EXE} ${INPUTS}


# Submit with the SBATCH configuration above to the gpu queue: "sbatch run.corigpu"
# Can also be ran with "./run.corigpu" to run with 1 CPU and 1 GPU.
srun ${EXE} ${INPUTS}



# NSight Systems
# ==============

# @@ Simple Example:
#srun nsys profile -o nsys_out.%q{SLURM_PROCID}.%q{SLURM_JOBID} ${EXE} ${INPUTS}

# @@ Recommended Example:
#srun nsys profile -c nvtx -p "<TINY_PROFILER_NAME>@*" -e NSYS_NVTX_PROFILER_REGISTER_ONLY=0 -o nsys_out.%q{SLURM_PROCID}.%q{SLURM_JOBID} ${EXE} ${INPUTS}

# @@ Discussion:
#   This will run nsys profile and store performance data in a qdrep file named after '-o'
#   Open using nsight-sys $(pwd)/nsys_out.#.######.qdrep

#   To capture the NVTX ranges, included in TINY_PROFILE objects, use:
#       "-e NSYS_NVTX_PROFILER_REGISTER_ONLY=0"
#   (TINY_PROFILE's NVTX regions do not use registered strings at this time.)

#   Nsight systems creates a timeline over a single, contiguous block of time.
#   The start of the timeline can be selected using TINY_PROFILER's NVTX markers with:
#     -c nvtx -p "region_name@*"
#   This will turn on the profiling analysis at the first instance of the TINY_PROFILER region
#   and run to the end of the program. To stop the analysis at the end of the same region, add:
#     -x true
#   Note: This will only analyze the first instance of the region, so "-x true" should be used
#   for specific analyses, or on more inclusive timers, e.g. a timer around a full timestep.

# @@ Documentation:
#   For NSight System profiling flags:
#      https://docs.nvidia.com/nsight-systems/profiling/index.html#cli-profile-command-switch-options
#   For NSight examples to launch profiling, including region limiting:
#      https://docs.nvidia.com/nsight-systems/profiling/index.html#example-interactive-cli-command-sequences

# Running NSight Systems on multiple ranks
# ========================================

# Run Nsight Systems only profiling on $PROFILE_RANK rank on a multi-rank job
#    **** Preferred for most basic use cases
#srun ./profile_1rank.sh ${EXE} ${INPUTS}

# Uncomment and copy the following lines into profile_1rank.sh
# Adjust the nsys command line as needed for your test case.
# #!/bin/bash
# PROFILE_RANK=0
# if [ $SLURM_PROCID == $PROFILE_RANK ]; then
#   nsys profile -o nsys_out.%q{SLURM_PROCID}.%q{SLURM_JOBID} "$@"
# else
#   "$@"
# fi

# NSight Compute
# ==============

# Run Nsight Compute:
#    **** This will do a A LOT of analysis. Unless you want the entire job ran 7 times
#    **** with full profiling, limit the kernels profiled with additional flags:
#    For filtering examples, see:
#    https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html#nvtx-filtering
#    For full list of profile options, see:
#    https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html#command-line-options-profile
#    Recommended: limit kernels tested within a given BL_PROFILER timer with "--nvtx-include <configuration>"
#      Note: Must use TINY_PROFILE=TRUE and nvtx region names are equal to BL_PROFILER timer names.
#srun nv-nsight-cu-cli -o cucli_out.%q{SLURM_PROCID}.%q{SLURM_JOBID} ${EXE} ${INPUTS}
